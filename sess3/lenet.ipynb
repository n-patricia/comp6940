{"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","from sklearn import decomposition\n","from sklearn import manifold\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from tqdm.notebook import tqdm, trange\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import copy\n","import random\n","import time"],"metadata":{"id":"tb7Fgtob1hyK","executionInfo":{"status":"ok","timestamp":1714319706273,"user_tz":-420,"elapsed":7563,"user":{"displayName":"Novi Patricia","userId":"16160040107027554899"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"alzbmfc91a9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZDCdCOjWFVnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8ZfcUitUFVdg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LeNet"],"metadata":{"id":"g3ugImllWni2"}},{"cell_type":"code","source":["class LeNet(nn.Module):\n","    def __init__(self, output_dim):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels=1,\n","                               out_channels=6,\n","                               kernel_size=5)\n","\n","        self.conv2 = nn.Conv2d(in_channels=6,\n","                               out_channels=16,\n","                               kernel_size=5)\n","\n","        self.fc_1 = nn.Linear(16 * 4 * 4, 120)\n","        self.fc_2 = nn.Linear(120, 84)\n","        self.fc_3 = nn.Linear(84, output_dim)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = F.relu(x)\n","        x = x.view(x.shape[0], -1)\n","        h = x\n","        x = self.fc_1(x)\n","        x = F.relu(x)\n","        x = self.fc_2(x)\n","        x = F.relu(x)\n","        x = self.fc_3(x)\n","        return x, h"],"metadata":{"id":"8UozrulB1a5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ROOT = '.data'\n","\n","train_data = datasets.MNIST(root=ROOT,\n","                            train=True,\n","                            download=True)\n","\n","mean = train_data.data.float().mean() / 255\n","std = train_data.data.float().std() / 255\n","\n","print(f'Calculated mean: {mean}')\n","print(f'Calculated std: {std}')"],"metadata":{"id":"cWZSMMZfFkGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transforms = transforms.Compose([\n","                            transforms.RandomRotation(5, fill=(0,)),\n","                            transforms.RandomCrop(28, padding=2),\n","                            transforms.ToTensor(),\n","                            transforms.Normalize(mean=[mean], std=[std])])\n","\n","test_transforms = transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize(mean=[mean], std=[std])])"],"metadata":{"id":"4HRXm1DaFlLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = datasets.MNIST(root=ROOT,\n","                            train=True,\n","                            download=True,\n","                            transform=train_transforms)\n","\n","test_data = datasets.MNIST(root=ROOT,\n","                           train=False,\n","                           download=True,\n","                           transform=test_transforms)"],"metadata":{"id":"4OjLdlzkFlAQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VALID_RATIO = 0.9\n","\n","n_train_examples = int(len(train_data) * VALID_RATIO)\n","n_valid_examples = len(train_data) - n_train_examples\n","\n","train_data, valid_data = data.random_split(train_data,\n","                                           [n_train_examples, n_valid_examples])"],"metadata":{"id":"VwFJPMGMGGQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_data = copy.deepcopy(valid_data)\n","valid_data.dataset.transform = test_transforms"],"metadata":{"id":"2dXSqNkMGG52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of validation examples: {len(valid_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"metadata":{"id":"6ID92KGjGSI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","train_iterator = data.DataLoader(train_data,\n","                                 shuffle=True,\n","                                 batch_size=BATCH_SIZE)\n","\n","valid_iterator = data.DataLoader(valid_data,\n","                                 batch_size=BATCH_SIZE)\n","\n","test_iterator = data.DataLoader(test_data,\n","                                batch_size=BATCH_SIZE)"],"metadata":{"id":"pjOtcEFoGSs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_filter(images, filter):\n","\n","    images = images = torch.cat([i.unsqueeze(0) for i in images],\n","                                dim=0).cpu()\n","    filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()\n","\n","    n_images = images.shape[0]\n","\n","    filtered_images = F.conv2d(images, filter)\n","\n","    fig = plt.figure(figsize=(20, 5))\n","\n","    for i in range(n_images):\n","\n","        ax = fig.add_subplot(2, n_images, i+1)\n","        ax.imshow(images[i].squeeze(0), cmap='bone')\n","        ax.set_title('Original')\n","        ax.axis('off')\n","\n","        image = filtered_images[i].squeeze(0)\n","\n","        ax = fig.add_subplot(2, n_images, n_images+i+1)\n","        ax.imshow(image, cmap='bone')\n","        ax.set_title('Filtered')\n","        ax.axis('off')"],"metadata":{"id":"8Jt_u6L3Gcp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_IMAGES = 5\n","\n","images = [image for image, label in [test_data[i] for i in range(N_IMAGES)]]"],"metadata":{"id":"afOPs-EcGgLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["horizontal_filter = [[-1, -2, -1],\n","                     [ 0,  0,  0],\n","                     [ 1,  2,  1]]\n","\n","plot_filter(images, horizontal_filter)"],"metadata":{"id":"DkCinF5FGicI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["horizontal_filter = [[ 1,  2,  1],\n","                     [ 0,  0,  0],\n","                     [-1, -2, -1]]\n","\n","plot_filter(images, horizontal_filter)"],"metadata":{"id":"NUEmLBGYGi4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vertical_filter = [[-1, 0, 1],\n","                   [-2, 0, 2],\n","                   [-1, 0, 1]]\n","\n","plot_filter(images, vertical_filter)"],"metadata":{"id":"y4VUNJsVGnnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vertical_filter = [[1, 0, -1],\n","                   [2, 0, -2],\n","                   [1, 0, -1]]\n","\n","plot_filter(images, vertical_filter)"],"metadata":{"id":"Q9iSrRi0Gnit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_subsample(images, pool_type, pool_size):\n","    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n","\n","    if pool_type.lower() == 'max':\n","        pool = F.max_pool2d\n","    elif pool_type.lower() in ['mean', 'avg']:\n","        pool = F.avg_pool2d\n","    else:\n","        raise ValueError(f'pool_type must be either max or mean, got: {pool_type}')\n","\n","    n_images = images.shape[0]\n","\n","    pooled_images = pool(images, kernel_size=pool_size)\n","\n","    fig = plt.figure(figsize=(20, 5))\n","\n","    for i in range(n_images):\n","\n","        ax = fig.add_subplot(2, n_images, i+1)\n","        ax.imshow(images[i].squeeze(0), cmap='bone')\n","        ax.set_title('Original')\n","        ax.axis('off')\n","\n","        image = pooled_images[i].squeeze(0)\n","\n","        ax = fig.add_subplot(2, n_images, n_images+i+1)\n","        ax.imshow(image, cmap='bone')\n","        ax.set_title('Subsampled')\n","        ax.axis('off')"],"metadata":{"id":"PY5E5LoVFVUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_subsample(images, 'max', 2)"],"metadata":{"id":"SuO7ixNlGv-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_subsample(images, 'avg', 2)"],"metadata":{"id":"eBuyuBQ3HF44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T9q7RRXxHMAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OUTPUT_DIM = 10\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LeNet(OUTPUT_DIM)\n","model = model.to(device)\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss()\n","criterion = criterion.to(device)"],"metadata":{"id":"ZT52Dxac1a19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(y_pred, y):\n","    top_pred = y_pred.argmax(1, keepdim=True)\n","    correct = top_pred.eq(y.view_as(top_pred)).sum()\n","    acc = correct.float() / y.shape[0]\n","    return acc"],"metadata":{"id":"-WDG_zRDP2g5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, device):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        y_pred, _ = model(x)\n","        loss = criterion(y_pred, y)\n","\n","        acc = calculate_accuracy(y_pred, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"1fxT9WxSCGba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion, device):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n","\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            y_pred, _ = model(x)\n","            loss = criterion(y_pred, y)\n","\n","            acc = calculate_accuracy(y_pred, y)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"0WdpGjJ3CGYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"N4F-aw0zCGUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 20\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in trange(EPOCHS, desc=\"Epochs\"):\n","\n","    start_time = time.monotonic()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","    end_time = time.monotonic()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"metadata":{"id":"Y4HVG8YmCGRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('best_model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"metadata":{"id":"IPAhT0yXPucf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_predictions(model, iterator, device):\n","    model.eval()\n","\n","    images = []\n","    labels = []\n","    probs = []\n","\n","    with torch.no_grad():\n","        for (x, y) in iterator:\n","\n","            x = x.to(device)\n","            y_pred, _ = model(x)\n","            y_prob = F.softmax(y_pred, dim=-1)\n","\n","            images.append(x.cpu())\n","            labels.append(y.cpu())\n","            probs.append(y_prob.cpu())\n","\n","    images = torch.cat(images, dim=0)\n","    labels = torch.cat(labels, dim=0)\n","    probs = torch.cat(probs, dim=0)\n","\n","    return images, labels, probs"],"metadata":{"id":"Mj2fT4YWIItP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EIxMMnBXIIqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GwcxGe3JIInb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vnuYos8kIIhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5jUkWf1bIIe3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2nhGsSjyIIbv"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNnPrCjuhz7CttvYsmSUSYv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}